# ä½¿ç”¨ IntelÂ® Extension for Transformers æ¨ç† GLM-4-9B-Chat æ¨¡å‹

æœ¬ç¤ºä¾‹ä»‹ç»å¦‚ä½•ä½¿ç”¨ IntelÂ® Extension for Transformers æ¨ç† GLM-4-9B-Chat æ¨¡å‹ã€‚

## è®¾å¤‡å’Œä¾èµ–æ£€æŸ¥

### ç›¸å…³æ¨ç†æµ‹è¯•æ•°æ®

**æœ¬æ–‡æ¡£çš„æ•°æ®å‡åœ¨ä»¥ä¸‹ç¡¬ä»¶ç¯å¢ƒæµ‹è¯•,å®é™…è¿è¡Œç¯å¢ƒéœ€æ±‚å’Œè¿è¡Œå ç”¨çš„æ˜¾å­˜ç•¥æœ‰ä¸åŒï¼Œè¯·ä»¥å®é™…è¿è¡Œç¯å¢ƒä¸ºå‡†ã€‚**

æµ‹è¯•ç¡¬ä»¶ä¿¡æ¯:

+ OS: Ubuntu 22.04 (æœ¬æ•™ç¨‹ä¸€å®šéœ€è¦åœ¨Linuxç¯å¢ƒä¸‹æ‰§è¡Œ)
+ Memory: 512GB 
+ Python: 3.10.12 
+ CPU: Intel(R) Xeon(R) Platinum 8358 CPU / 12th Gen Intel i5-12400

## å®‰è£…ä¾èµ–

åœ¨å¼€å§‹æ¨ç†ä¹‹å‰ï¼Œè¯·ä½ å…ˆå®‰è£…`basic_demo`ä¸­çš„ä¾èµ–ï¼ŒåŒæ—¶æ‚¨éœ€è¦å®‰è£…æœ¬ç›®å½•ä¸‹çš„ä¾èµ–é¡¹ï¼š
```shell
pip install -r requirements.txt
```

## è¿è¡Œæ¨¡å‹æ¨ç†

```shell
python itrex_cli_demo.py
```

å¦‚æœæ‚¨æ˜¯ç¬¬ä¸€æ¬¡æ¨ç†ï¼Œä¼šæœ‰ä¸€æ¬¡æ¨¡å‹è½¬æ¢æƒé‡çš„è¿‡ç¨‹ï¼Œè½¬æ¢åçš„æ¨¡å‹æƒé‡å­˜æ”¾åœ¨`runtime_outputs`æ–‡ä»¶å¤¹ä¸‹ï¼Œè¿™å¤§æ¦‚ä¼šæ¶ˆè€—`60G`çš„ç¡¬ç›˜ç©ºé—´ã€‚
è½¬æ¢å®Œæˆåï¼Œæ–‡ä»¶å¤¹ä¸‹æœ‰ä¸¤ä¸ªæ–‡ä»¶ï¼š
+ ne_chatglm2_f32.bin 52G(å¦‚æœæ‚¨ä¸ä½¿ç”¨FP32è¿›è¡Œæ¨ç†ï¼Œå¯ä»¥åˆ æ‰è¿™ä¸ªæ–‡ä»¶)
+ ne_chatglm2_q_nf4_bestla_cfp32_sym_sfp32_g32.bin 8.1G

å¦‚æœæ‚¨ä¸æ˜¯ç¬¬ä¸€æ¬¡æ¨ç†ï¼Œåˆ™ä¼šè·³è¿‡è¿™ä¸ªæ­¥éª¤ï¼Œç›´æ¥å¼€å§‹å¯¹è¯ï¼Œæ¨ç†æ•ˆæœå¦‚ä¸‹ï¼š
```shell
Welcome to the CLI chat. Type your messages below.

User: ä½ å¥½
AVX:1 AVX2:1 AVX512F:1 AVX512BW:1 AVX_VNNI:0 AVX512_VNNI:1 AMX_INT8:0 AMX_BF16:0 AVX512_BF16:0 AVX512_FP16:0
beam_size: 1, do_sample: 1, top_k: 40, top_p: 0.900, continuous_batching: 0, max_request_num: 1, early_stopping: 0, scratch_size_ratio: 1.000
model_file_loader: loading model from runtime_outs/ne_chatglm2_q_nf4_bestla_cfp32_sym_sfp32_g32.bin
Loading the bin file with NE format...
load_ne_hparams  0.hparams.n_vocab = 151552                        
load_ne_hparams  1.hparams.n_embd = 4096                          
load_ne_hparams  2.hparams.n_mult = 0                             
load_ne_hparams  3.hparams.n_head = 32                            
load_ne_hparams  4.hparams.n_head_kv = 0                             
load_ne_hparams  5.hparams.n_layer = 40                            
load_ne_hparams  6.hparams.n_rot = 0                             
load_ne_hparams  7.hparams.ftype = 0                             
load_ne_hparams  8.hparams.max_seq_len = 131072                        
load_ne_hparams  9.hparams.alibi_bias_max = 0.000                         
load_ne_hparams  10.hparams.clip_qkv = 0.000                         
load_ne_hparams  11.hparams.par_res = 0                             
load_ne_hparams  12.hparams.word_embed_proj_dim = 0                             
load_ne_hparams  13.hparams.do_layer_norm_before = 0                             
load_ne_hparams  14.hparams.multi_query_group_num = 2                             
load_ne_hparams  15.hparams.ffn_hidden_size = 13696                         
load_ne_hparams  16.hparams.inner_hidden_size = 0                             
load_ne_hparams  17.hparams.n_experts = 0                             
load_ne_hparams  18.hparams.n_experts_used = 0                             
load_ne_hparams  19.hparams.n_embd_head_k = 0                             
load_ne_hparams  20.hparams.norm_eps = 0.000000                      
load_ne_hparams  21.hparams.freq_base = 5000000.000                   
load_ne_hparams  22.hparams.freq_scale = 1.000                         
load_ne_hparams  23.hparams.rope_scaling_factor = 0.000                         
load_ne_hparams  24.hparams.original_max_position_embeddings = 0                             
load_ne_hparams  25.hparams.use_yarn = 0                             
load_ne_vocab    26.vocab.bos_token_id = 1                             
load_ne_vocab    27.vocab.eos_token_id = 151329                        
load_ne_vocab    28.vocab.pad_token_id = 151329                        
load_ne_vocab    29.vocab.sep_token_id = -1                            
init: hparams.n_vocab         = 151552
init: hparams.n_embd          = 4096
init: hparams.n_mult          = 0
init: hparams.n_head          = 32
init: hparams.n_layer         = 40
init: hparams.n_rot           = 0
init: hparams.ffn_hidden_size = 13696
init: n_parts    = 1
load: ctx size   = 16528.38 MB
load: layers[0].ffn_fusion    = 1
load: scratch0   = 4096.00 MB
load: scratch1   = 2048.00 MB
load: scratch2   = 4096.00 MB
load: mem required  = 26768.38 MB (+ memory per state)
.............................................................................................
model_init_from_file: support_bestla_kv = 1
kv_cache_init: run_mha_reordered = 1
model_init_from_file: kv self size =  690.00 MB
Assistant:
ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ã€‚æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ
```
